{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJQlh7wfjqYm"
   },
   "source": [
    "### KHBM 2022 Summer school\n",
    "# MVPA & RSA\n",
    "\n",
    "In this lab, you will learn about **Multi-Voxel Pattern Analysis (MVPA)** and **Representational Similarity Analysis (RSA)**, two analysis methods to examine activation patterns across multiple voxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Getting started\n",
    "Download the modules and data will be using for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy          # NumPy for scientific computing\n",
    "!pip install matplotlib     # Matplotlib for data visualization\n",
    "!pip install nibabel        # Nibabel for neuroimaging data I/O\n",
    "!pip install nilearn        # Nilearn for neuroimaging data visualization\n",
    "\n",
    "use_colab = True            # Set [True] if you're using Google Colab\n",
    "if use_colab:\n",
    "    data_root = 'MVPA-RSA_tutorial/data/'\n",
    "    !git clone https://github.com/jwparks/MVPA-RSA_tutorial     # Get tutorial data\n",
    "    !apt-get install tree\n",
    "else:\n",
    "    data_root = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check your data structure\n",
    "Now make sure you have all the data need for the tutorial. Two fMRI data and Brainnetome cortical atlas(2016) are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "subject_id = 'sub-01'\n",
    "task = 'FOSS'\n",
    "file_exists = []\n",
    "for run in ['1', '2']:\n",
    "    file_exists.append(os.path.exists(data_root+\n",
    "                       subject_id+'/'+subject_id+\n",
    "                       '_task-'+task+\n",
    "                       '_run-'+run+'_preprocessed.nii.gz'))\n",
    "file_exists.append(os.path.exists(data_root+\"Brainnetome_atlas.nii\"))\n",
    "print(\"Data validation: \", file_exists)\n",
    "print(\" \")\n",
    "if use_colab:\n",
    "    !tree {data_root}\n",
    "else:\n",
    "    !tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrurcRNVTc0n"
   },
   "source": [
    "## Why and when is a multivariate pattern useful? \n",
    "\n",
    "Suppose that there are fMRI data measured from two voxels in each of the two experimental conditions.\n",
    "If the experimental conditions you are interested in induce larger activation in a particular voxel than other conditions do, you can expect the results shown in the figure below.\n",
    "\n",
    "### Simulation 1: Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKRBMLdMTc0n",
    "outputId": "d21a3b61-49c8-4039-8b35-407041fee59f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_hist(x, y, ax, ax_histx, ax_histy, label):\n",
    "    # from https://matplotlib.org/stable/gallery/lines_bars_and_markers/scatter_hist.html\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "    \n",
    "    ax.scatter(x, y, s=40, label=label)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Activity in voxel 1')\n",
    "    ax.set_ylabel('Activity in voxel 2')\n",
    "    binwidth = 0.25\n",
    "    xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "    lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    ax_histx.hist(x, bins=bins)\n",
    "    ax_histy.hist(y, bins=bins, orientation='horizontal')\n",
    "    return ax\n",
    "    \n",
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.0\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "np.random.seed(0)\n",
    "fig = plt.figure(figsize=(4, 4), dpi=150)\n",
    "\n",
    "ax = fig.add_axes(rect_scatter)\n",
    "ax_histx = fig.add_axes(rect_histx, sharex=ax)\n",
    "ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "\n",
    "# condition A (Red)\n",
    "num_datapoints = 40\n",
    "voxel_1_data = np.random.normal(loc=-1.0, scale=0.5, size=30)\n",
    "voxel_2_data = np.random.normal(loc=1.0, scale=0.5, size=30)\n",
    "\n",
    "scatter_hist(voxel_1_data, voxel_2_data, ax, ax_histx, ax_histy, label='condition A')\n",
    "\n",
    "voxel_1_data = np.random.normal(loc=1.0, scale=0.5, size=30)\n",
    "voxel_2_data = np.random.normal(loc=-1.0, scale=0.5, size=30)\n",
    "\n",
    "scatter_hist(voxel_1_data, voxel_2_data, ax, ax_histx, ax_histy, label='condition B')\n",
    "ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV0Kik7HTc0p"
   },
   "source": [
    "As can be seen from the simulation above, you can separate the two experimental conditions by the difference in the activity of a single voxel.\n",
    "\n",
    "On the other hand, what about the following situation?\n",
    "### Similation 2: Multivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuvwZ23OTc0q",
    "outputId": "ea4d54b5-8ad3-4d80-f0e2-358713a08c17",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "fig = plt.figure(figsize=(4,4), dpi=150)\n",
    "\n",
    "ax = fig.add_axes(rect_scatter)\n",
    "ax_histx = fig.add_axes(rect_histx, sharex=ax)\n",
    "ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "\n",
    "# condition A (Red)\n",
    "num_datapoints = 40\n",
    "voxel_1_data = np.random.normal(loc=-0.4, scale=1.0, size=30)\n",
    "voxel_2_data = voxel_1_data + np.random.normal(loc=-0.4, scale=0.5, size=30)\n",
    "\n",
    "scatter_hist(voxel_1_data, voxel_2_data, ax, ax_histx, ax_histy, label='condition A')\n",
    "\n",
    "voxel_1_data = np.random.normal(loc=-0.4, scale=1.0, size=30)\n",
    "voxel_2_data = voxel_1_data + np.random.normal(loc=0.4, scale=0.5, size=30)\n",
    "\n",
    "scatter_hist(voxel_1_data, voxel_2_data, ax, ax_histx, ax_histy, label='condition B')\n",
    "ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAGLHD6sTc0q"
   },
   "source": [
    "The results of the second simulation show no significant difference in activity between the two conditions in any voxel. But as in the scatter plot, you can separate the two conditions by comparing activity of the two voxels together. In this simulation, the condition A evokes larger activity in voxel 1 than in voxel 2.\n",
    "\n",
    "The Multivariate data analysis is needed if your psychological hypothesis and experimental design is involved in the representation similar to the second simulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJSai1kkufT3"
   },
   "source": [
    "## MVPA (Multi-Voxel Pattern Analysis)\n",
    "MVPA or multi-voxel pattern analysis is an analysis method that classifies activity patterns across multiple voxels into specific labels, such as experimental conditions. In machine learning, it is known as decoding or classification.\n",
    "\n",
    "MVPA consists of training and testing steps, just as other machine learning methods do. First, in the training part, you need to train a classifier that predicts a specific label from the activity pattern of the voxels. Susequently, in the test part, you can check the accurracy of classification performance using the brain data (e.g., activity patterns) that was not used for training.\n",
    "\n",
    "What does it mean if the classifier can successfully predict certain labels, such as experimental conditions, from brain data? I recommend you to think it over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVQ-sUWnufT6"
   },
   "source": [
    "### Data extraction\n",
    "For the analysis, we will use each trial of the FOSS experiment as input data. We create a classification model that predicts the experimental condition (e.g., Face, Objects, Scene, or Scrambled object) using the brain data and check the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3M5Cnf5Tc0s",
    "outputId": "b6f322a7-e371-4754-e2e9-130fa7bf7bd3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "FOSS_TR = 2\n",
    "FOSS_num_TRs = 147\n",
    "FOSS_num_runs = 2\n",
    "FOSS_stimulus_duration = 14\n",
    "FOSS_1_stimulus_order = ['x', 'F', 'O', 'S', 'P', \n",
    "                         'x', 'O', 'P', 'F', 'S', \n",
    "                         'x', 'S', 'P', 'F', 'O', \n",
    "                         'x', 'P', 'S', 'O', 'F', \n",
    "                         'x']\n",
    "FOSS_2_stimulus_order = ['x', 'P', 'S', 'O', 'F', \n",
    "                         'x', 'S', 'P', 'F', 'O', \n",
    "                         'x', 'O', 'P', 'F', 'S',\n",
    "                         'x', 'F', 'O', 'S', 'P', \n",
    "                         'x']\n",
    "FOSS_stimulus_order = np.repeat(FOSS_1_stimulus_order + FOSS_2_stimulus_order, 7)\n",
    "FOSS_stimulus_matrix = np.zeros((5, 21*2*7))\n",
    "for i, stimulus in enumerate(FOSS_stimulus_order):\n",
    "    if stimulus=='x':\n",
    "        FOSS_stimulus_matrix[0,i] = 1\n",
    "    elif stimulus=='F':\n",
    "        FOSS_stimulus_matrix[1,i] = 1\n",
    "    elif stimulus=='O':\n",
    "        FOSS_stimulus_matrix[2,i] = 1\n",
    "    elif stimulus=='P':\n",
    "        FOSS_stimulus_matrix[3,i] = 1\n",
    "    elif stimulus=='S':\n",
    "        FOSS_stimulus_matrix[4,i] = 1\n",
    "\n",
    "plt.figure(figsize=(24,4), dpi=150)\n",
    "plt.imshow(FOSS_stimulus_matrix, aspect='auto', cmap='Greys_r')\n",
    "plt.yticks(np.arange(5), ['Fixation', 'Face', 'Object', 'Place', 'Scrambled'])\n",
    "plt.xticks(np.linspace(0,294-7,21*2), [str(i) for i in np.linspace(0,294-7,21*2, dtype=np.int)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIto6KNbTc0s"
   },
   "source": [
    "### Multi-voxel patterns in ventral temporal cortex\n",
    "Let's extract the mask for the ventral temporal cortex from the brainnetome atlas and see what actviity patterns in the ventral temporal cortex represent each condition of the FOSS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wsw0ZM1NTc0s",
    "outputId": "bae546e8-deb0-4a6a-eb03-b3a563f94e6e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "\n",
    "bn_atlas = nib.load(data_root+'Brainnetome_atlas.nii')\n",
    "bn_atlas_data = bn_atlas.get_fdata()\n",
    "\n",
    "VT_mask = np.zeros(bn_atlas_data.shape)\n",
    "for roi in range(89, 121):\n",
    "    if roi % 2 ==0:\n",
    "        VT_mask[bn_atlas_data==roi] = 1\n",
    "    \n",
    "VT_mask = nib.Nifti1Image(VT_mask, bn_atlas.affine)\n",
    "plotting.view_img(VT_mask, symmetric_cmap=False,\n",
    "                  resampling_interpolation='nearest',\n",
    "                  cut_coords=(34, -36, -16), draw_cross=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the timeseries of corresponding voxels using the VT mask defined above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QqT15kFTc0t",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "subject_id = 'sub-01'\n",
    "task = 'FOSS'\n",
    "FOSS_data_VT_voxels = np.empty((0, np.sum(VT_mask.get_fdata()==1)))\n",
    "for run in ['1', '2']:\n",
    "    FOSS_data = nib.load(data_root+\n",
    "                         subject_id+'/'+subject_id+\n",
    "                         '_task-'+task+\n",
    "                         '_run-'+run+\n",
    "                         '_preprocessed.nii.gz')\n",
    "\n",
    "    FOSS_data_VT_voxels = np.concatenate([FOSS_data_VT_voxels,\n",
    "                                          FOSS_data.get_fdata()[VT_mask.get_fdata()==1,:].T], axis=0)\n",
    "print(FOSS_data_VT_voxels.shape) # should be (#timepoints, #voxels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1yJZplKTc0t"
   },
   "source": [
    "### Multi-voxel patterns: Face condition\n",
    "Now, visualize the Multi-voxel pattern corresponding to `Face` condition. The colorbar indiciates mean BOLD response of multi-voxel pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVziqTe_Tc0u",
    "outputId": "a8ac92cd-2a42-4b0e-f130-65df16fe4671",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_trials(ROI_data, onset, duration):\n",
    "    offset = 3\n",
    "    data = ROI_data[onset+offset:onset+offset+duration,:]\n",
    "    return data.mean(axis=0)\n",
    "\n",
    "Face_trial = get_trials(FOSS_data_VT_voxels, 7, 7)\n",
    "print(Face_trial.shape)\n",
    "\n",
    "Face_pattern = np.zeros(bn_atlas_data.shape)\n",
    "Face_pattern[VT_mask.get_fdata()==1] = Face_trial\n",
    "Face_pattern = nib.Nifti1Image(Face_pattern, bn_atlas.affine)\n",
    "plotting.view_img(Face_pattern, cmap='jet', cut_coords=(34, -36, -16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkma86oATc0u"
   },
   "source": [
    "### Multi-voxel patterns: Object, Place condition\n",
    "Likewise, you can visualize the Multi-voxel pattern corresponding to the `Object` and `Place` condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0U3h8_bTc0u",
    "outputId": "9d502e7e-0726-4d3a-b532-d83e517c72f7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Object_trial = get_trials(FOSS_data_VT_voxels, 14, 7)\n",
    "print(Object_trial.shape)\n",
    "\n",
    "Object_pattern = np.zeros(bn_atlas_data.shape)\n",
    "Object_pattern[VT_mask.get_fdata()==1] = Object_trial\n",
    "Object_pattern = nib.Nifti1Image(Object_pattern, bn_atlas.affine)\n",
    "plotting.view_img(Object_pattern, cmap='jet', cut_coords=(34, -36, -16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Place_trial = get_trials(FOSS_data_VT_voxels, 28, 7)\n",
    "print(Place_trial.shape)\n",
    "\n",
    "Place_pattern = np.zeros(bn_atlas_data.shape)\n",
    "Place_pattern[VT_mask.get_fdata()==1] = Place_trial\n",
    "Place_pattern = nib.Nifti1Image(Place_pattern, bn_atlas.affine)\n",
    "plotting.view_img(Place_pattern, cmap='jet', cut_coords=(34, -36, -16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extract all trials\n",
    "You can extract the data you want to use for your analysis by using the `get_trials()` function and the `onset` and `duration` of the desired trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Face_trials = []\n",
    "Object_trials = []\n",
    "Place_trials = []\n",
    "Scrambled_trials = []\n",
    "for t, trial in enumerate(FOSS_1_stimulus_order + FOSS_2_stimulus_order):\n",
    "    if trial=='F':\n",
    "        Face_trials.append(get_trials(FOSS_data_VT_voxels, t*7, 7))\n",
    "    elif trial=='O':\n",
    "        Object_trials.append(get_trials(FOSS_data_VT_voxels, t*7, 7))\n",
    "    elif trial=='P':\n",
    "        Place_trials.append(get_trials(FOSS_data_VT_voxels, t*7, 7))\n",
    "    elif trial=='S':\n",
    "        Scrambled_trials.append(get_trials(FOSS_data_VT_voxels, t*7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnNAvvHVTc0w"
   },
   "source": [
    "### Training the model \n",
    "In the data analysis using machine learning methods, such as MVPA, data must be divided into independent training and test dataset. There are many ways to divide the data, but 10-fold cross-validation was used here.\n",
    "\n",
    "In this lab, a linear support vector machine (SVM) is used as a classification algorithm. To calculate the performance of the model, you can calculate the classification accuracy of the training and test dataset and plot a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4YPrMTJTc0w",
    "outputId": "06b55571-abf2-4232-aa82-cd80b7c10bf8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC             \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.random.seed(13) # for reproducibility\n",
    "\n",
    "X = np.vstack([Face_trials, \n",
    "               Object_trials, \n",
    "               Place_trials,\n",
    "               Scrambled_trials])\n",
    "\n",
    "y = np.repeat(['F', 'O', 'P', 'S'], 8)\n",
    "\n",
    "KF_10 = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "confusion_mat = []\n",
    "\n",
    "# Step 1: Define cross-validation scheme\n",
    "for train_index, test_index in KF_10.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Step 2: Build linear SVM model\n",
    "    SVM_model = LinearSVC()\n",
    "\n",
    "    # Step 3: Training SVM with training dataset\n",
    "    SVM_model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 4: Classification accuracy for training dataset \n",
    "    train_accuracy.append(SVM_model.score(X_train, y_train))\n",
    "\n",
    "    # Step 5: Classification accuracy for test dataset \n",
    "    test_accuracy.append(SVM_model.score(X_test, y_test))\n",
    "\n",
    "    # Step 6: confusion_matrix\n",
    "    confusion_mat.append(confusion_matrix(y_test, SVM_model.predict(X_test), labels=['F','O','P','S']))\n",
    "        \n",
    "print('Average classification accuracy for train set: ', np.mean(train_accuracy))\n",
    "print('Average classification accuracy for test set: ', np.mean(test_accuracy))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3,3), dpi=150)\n",
    "plt.imshow(np.sum(confusion_mat, axis=0), cmap='Blues')\n",
    "plt.xticks(np.arange(4), labels=['Face','Object','Place','Scrambled'], rotation=45)\n",
    "plt.yticks(np.arange(4), labels=['Face','Object','Place','Scrambled'])\n",
    "plt.title('MVPA: Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.text(j,i, np.sum(confusion_mat, axis=0)[i,j], va='center', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the weight map which voxel was effective in decoding certain conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "weight_idx = 0  # 0:Face, 1:Object, 2:Place, 3: Scrambled\n",
    "\n",
    "weight_map = np.zeros(bn_atlas_data.shape)\n",
    "weight_map[VT_mask.get_fdata()==1] = SVM_model.coef_[weight_idx,:]\n",
    "weight_map = nib.Nifti1Image(weight_map, bn_atlas.affine)\n",
    "plotting.view_img(weight_map, cmap='jet', cut_coords=(34, -36, -16), draw_cross=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaIJTN3jTc0w"
   },
   "source": [
    "The accuracy of the classification model predicting the experimental conditions from the FOSS data was higher than the chance level. Again, think about what these results mean in terms of cognitive processes that might be involved here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlcWr2kRTc0x"
   },
   "source": [
    "## RSA (Representational Similarity Analysis)\n",
    "Unlike MVPA, RSA is not an analysis method using machine learning. However, it is an analysis method that directly calculates the similarity between the brain patterns for different experimental conditions and compares it with the hypothetical (model) similarity (This is called meta-correlation.).\n",
    "\n",
    "You can create various model similarity matrices for the FOSS data. For example, assuming that each experimental condition is independent of each other, a similarity matrix with only diagonal components can be hypothesized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN8lWZjcTc0x",
    "outputId": "c34beebd-2af2-41ee-a346-bb13aa414906"
   },
   "outputs": [],
   "source": [
    "hypothetical_similarity = np.zeros((4,4))\n",
    "np.fill_diagonal(hypothetical_similarity, 1)\n",
    "\n",
    "plt.figure(figsize=(10,3), dpi=150)\n",
    "plt.subplot(131)\n",
    "plt.title('Model matrix 1')\n",
    "plt.imshow(hypothetical_similarity)\n",
    "plt.xticks(np.arange(4), ['Face', 'Object', 'Place', 'Scrambled'], fontsize=9)\n",
    "plt.yticks(np.arange(4), ['Face', 'Object', 'Place', 'Scrambled'], rotation=270, fontsize=9, va='center')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Model matrix 2')\n",
    "hypothetical_similarity[0,1] = 1\n",
    "hypothetical_similarity[1,0] = 1\n",
    "plt.imshow(hypothetical_similarity)\n",
    "plt.xticks(np.arange(4), ['Face', 'Object', 'Place', 'Scrambled'], fontsize=9)\n",
    "plt.yticks(np.arange(4), ['Face', 'Object', 'Place', 'Scrambled'], rotation=270, fontsize=9, va='center')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Model matrix 3')\n",
    "hypothetical_similarity[2,3] = 1\n",
    "hypothetical_similarity[3,2] = 1\n",
    "plt.imshow(hypothetical_similarity)\n",
    "plt.xticks(np.arange(4), ['Face', 'Object', 'Place', 'Scrambled'], fontsize=9)\n",
    "plt.yticks(np.arange(4), ['Face', 'Object', 'Place', 'Scrambled'], rotation=270, fontsize=9, va='center')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IC7SAk6ETc0x"
   },
   "source": [
    "The multi-voxel pattern data can be thought of as a vector present in the voxel space. And the similarity between vectors can be calculated by different similarity measures such as cosine similarity, euclidean distance, etc. In this lab, we will use cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PISpTXDaTc0x",
    "outputId": "f12d62ec-4ef1-42fc-8c74-ac29844bb7c0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "cosine_similarity_matrix  = cosine_similarity(X)\n",
    "\n",
    "print('Cosine similarity matrix: ', cosine_similarity_matrix.shape)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(cosine_similarity_matrix)\n",
    "plt.clim(0,1)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xticks([0, 8, 16, 24], ['Face', 'Object', 'Place', 'Scrambled'], ha='left')\n",
    "plt.yticks([0, 8, 16, 24], ['Face', 'Object', 'Place', 'Scrambled'], rotation=270)\n",
    "\n",
    "for line in [0, 8, 16, 24]:\n",
    "    plt.axhline(line-0.5, c='w')\n",
    "    plt.axvline(line-0.5, c='w')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eT680nyvjqY-"
   },
   "source": [
    "# Recommended reading\n",
    "- https://dartbrains.org/content/Multivariate_Prediction.html\n",
    "- https://dartbrains.org/content/RSA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MVPA-RSA_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}